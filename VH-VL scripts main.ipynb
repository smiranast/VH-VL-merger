{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f802e-a16e-4eb9-9084-470a4a2b46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f9d69-ac6d-4635-a505-7ca2b497bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp1_list = # list of amp1 file names before _R1\n",
    "amp2_list = # list of amp2 file names before _R1\n",
    "\n",
    "samples = # sample names\n",
    "path = # dir with amp1_list and amp2_list files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65384aa5-40ee-4b66-8e50-e576093bc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp1_list = np.array(amp1_list)\n",
    "amp2_list = np.array(amp2_list)\n",
    "samples = np.array(samples)\n",
    "amp1_list, amp2_list, samples = list(amp1_list), list(amp2_list), list(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef87598-d1e2-4a10-b6eb-1f6a3d03d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for amp1, amp2, sample in tqdm_notebook(zip(amp1_list, amp2_list, samples), total=len(samples)):\n",
    "    \n",
    "    amp1H_file = pd.read_csv(path + amp1 + \"_2.clonotypes.IGH.txt\", sep=\"\\t\")\n",
    "    \n",
    "    amp2H_file = pd.read_csv(path + amp2 + \"_IGH.alignments.txt\", sep=\"\\t\")\n",
    "    amp2Hc_file = pd.read_csv(path + amp2 + \"_IGH.clonotypes.IGH.txt\", sep=\"\\t\")\n",
    "    amp2KL_file = pd.read_csv(path + amp2 + \"_IGKL.alignments.txt\", sep=\"\\t\")\n",
    "\n",
    "    amp1H_file.drop(columns=[\"bestCHit\", \"cloneCount\", \"cloneFraction\", \"cloneId\"], inplace=True)\n",
    "    amp2H_file = amp2H_file[[\"cloneId\", \"readId\",\"nSeqCDR3\", \"bestJHit\"]] # witout V/D matches\n",
    "    amp2Hc_file = amp2Hc_file[[\"cloneId\", \"cloneCount\", \"cloneFraction\"]]\n",
    "    amp2H_file = amp2H_file.merge(amp2Hc_file, on=[\"cloneId\"])\n",
    "    \n",
    "    \n",
    "    H_file = amp2H_file.add_prefix(\"IGH_\")\n",
    "\n",
    "    amp2KL_file = amp2KL_file.loc[amp2KL_file[\"cloneId\"] != -1, [\"cloneId\", \"readId\", \"nSeqCDR3\"]]\n",
    "    \n",
    "    amp2KL_file_c = pd.concat([pd.read_csv(path + amp2 + \"_IGKL.clonotypes.IGK.txt\", sep=\"\\t\"),\n",
    "                              pd.read_csv(path + amp2 + \"_IGKL.clonotypes.IGL.txt\", sep=\"\\t\")])\n",
    "\n",
    "    amp2KL_file_c.drop(columns=[\"bestDHit\", \"bestCHit\"], inplace=True)\n",
    "    KL_file = amp2KL_file.merge(amp2KL_file_c, on=[\"cloneId\", \"nSeqCDR3\"])\n",
    "    KL_file = KL_file.add_prefix(\"IGKL_\")\n",
    "\n",
    "    \n",
    "    \n",
    "    df_total = H_file.merge(KL_file, left_on=\"IGH_readId\", right_on=\"IGKL_readId\")\n",
    "    print(len(df_total[\"IGH_readId\"].unique()))\n",
    "    df_total.drop(columns=[\"IGH_readId\", \"IGKL_readId\"], inplace=True)\n",
    "\n",
    "    IGH_cols = [_ for _ in list(df_total.columns) if \"IGH\" in _]\n",
    "    IGKL_cols = [_ for _ in list(df_total.columns) if \"IGKL\" in _]\n",
    "    \n",
    "    \n",
    "    df_total = df_total.groupby(IGH_cols + IGKL_cols).size().reset_index(name='match')\n",
    "    df_total['IGKL_chains'] = df_total['IGKL_bestJHit'].str[:3]\n",
    "    \n",
    "    # Merging by the identical CDR3aa\n",
    "    cols = [col for col in df_total.columns if any(s in col for s in [\"cloneId\", \"best\", \"nSeqCDR3\", \"chains\", \"targetSequences\"])]\n",
    "    df_total = df_total.groupby([\"IGH_aaSeqCDR3\",\"IGKL_aaSeqCDR3\"]).agg({\"IGH_cloneCount\":\"sum\", \"IGKL_cloneCount\":\"sum\",\n",
    "                                                         \"IGH_cloneFraction\":\"sum\", \"IGKL_cloneFraction\":\"sum\",\n",
    "                                                         \"match\":\"sum\",\n",
    "                                                         \"IGH_cloneId\":\"unique\", \"IGKL_cloneId\":\"unique\",\n",
    "                                                         \"IGKL_chains\":\"unique\",\n",
    "                                                         \"IGH_bestVHit\":\"unique\", \"IGH_bestDHit\":\"unique\", \"IGH_bestJHit\":\"unique\",\n",
    "                                                         \"IGKL_bestVHit\":\"unique\", \"IGKL_bestJHit\":\"unique\",\n",
    "                                                         \"IGH_nSeqCDR3\":\"unique\", \"IGH_targetSequences\":\"unique\",\n",
    "                                                         \"IGKL_nSeqCDR3\":\"unique\", \"IGKL_targetSequences\":\"unique\"\n",
    "                                                         })\n",
    "    for col in cols:\n",
    "        df_total[col] = [\";\".join(df_total[col][i].astype(str)) for i in range(len(df_total))]\n",
    "    df_total = df_total.reset_index()\n",
    "    \n",
    "    # Filter clones with a low count\n",
    "    df_total = df_total.loc[(df_total[\"IGH_cloneCount\"] > 2) & (df_total[\"IGKL_cloneCount\"] > 2)]\n",
    "    \n",
    "    \n",
    "    df_total[\"IGH_matchFrac\"] = df_total[\"match\"] / df_total[\"IGH_cloneCount\"]\n",
    "    df_total[\"IGKL_matchFrac\"] = df_total[\"match\"] / df_total[\"IGKL_cloneCount\"]\n",
    "    \n",
    "    df_total = df_total[[\"IGH_cloneId\", \"IGH_cloneCount\", \"IGH_cloneFraction\", \"IGH_bestVHit\", \"IGH_bestDHit\", \"IGH_bestJHit\", \"IGH_nSeqCDR3\", \"IGH_aaSeqCDR3\", \"IGH_targetSequences\",\n",
    "                         \"IGKL_cloneId\", \"IGKL_chains\", \"IGKL_cloneCount\", \"IGKL_cloneFraction\", \"IGKL_bestVHit\", \"IGKL_bestJHit\", \"IGKL_nSeqCDR3\", \"IGKL_aaSeqCDR3\", \"IGKL_targetSequences\", \"IGH_matchFrac\",  \"IGKL_matchFrac\", \"match\"]]\n",
    "\n",
    "    df_total.rename(columns={\"IGKL_cloneCount\":\"IGKL_count\",\n",
    "                            \"IGH_cloneFraction\":\"IGH_freq\",\n",
    "                             \"IGKL_cloneFraction\":\"IGKL_freq\"}, inplace=True)\n",
    "    \n",
    "    df_total[\"IGKL_sym\"] = df_total[\"IGH_freq\"] / (df_total[\"IGKL_freq\"] * df_total[\"IGKL_matchFrac\"] )\n",
    "    df_total[\"IGH_sym\"] = df_total[\"IGH_freq\"] * df_total[\"IGH_matchFrac\"] / df_total[\"IGKL_freq\"]\n",
    "    \n",
    "    df_total[\"IGKL_symNorm\"] = df_total[\"IGKL_sym\"].apply(lambda x: 100**x if x <= 1 else 100**(1/x))\n",
    "    df_total[\"IGH_symNorm\"] = df_total[\"IGH_sym\"].apply(lambda x: 100**x if x <= 1 else 100**(1/x))\n",
    "    \n",
    "    df_total[\"signal\"] = df_total[\"IGKL_matchFrac\"] / df_total[\"IGH_freq\"]\n",
    "    \n",
    "    df_total[\"symNorm_HMean\"] = 2*df_total[\"IGKL_symNorm\"]*df_total[\"IGH_symNorm\"]/(df_total[\"IGKL_symNorm\"] + df_total[\"IGH_symNorm\"])\n",
    "    \n",
    "    df_total = df_total.sort_values(by=[\"IGH_cloneId\",\"IGKL_cloneId\"]).reset_index(drop=True)\n",
    "    df_total.to_csv(path + sample + '_IGH-fusion_result.collapsed.txt', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b4b31-492e-4533-b10d-d8fe79449127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
